# Linear Models

Linear models describe the relation between two variables. 
In a non-technical description we can think about linear model like:

> Find a line that is as close as possible to all the points of a scatterplot.


```{r}
#| echo: false
#| message: false
#| warning: false

library(dplyr)
library(ggplot2)

bd = read.csv("data/crop_species.csv")

bd = bd %>% mutate(Abundance = AraInd + CaraInd + IsoMyrInd,
              Species = AraSpec, CaraSpec, IsoMyrSpec)


ggplot(bd, aes(Abundance, Species))+
    geom_point()+
    geom_smooth(method = "lm", se = FALSE)+
    scale_x_continuous(limits = c(0,600))+
    theme_bw()
```


For example, we can use a linear model to depict the relation between the amount of samples animals and the number of different species found in a given area. To create a linear model, we need two vectors (here as two columns of a data.frame) with the matching data pairs (Abundance and Species Number). The `lm` function then takes a [formula](R08_formula.qmd) with the vector/column names separated by `~`.
You can interpret the `~` in this case _as a function of_. So `lm(Species ~ Abundance)` means: Give me the number of species as a function of species abundance. 


```{r}
#| echo: true
#| message: false
#| warning: false

library(dplyr)
bd = read.csv("data/crop_species.csv")

bd = bd %>% mutate(Abundance = AraInd + CaraInd + IsoMyrInd,
              Species = AraSpec, CaraSpec, IsoMyrSpec)

lmod = lm(Species ~ Abundance, bd)
lmod
```

## Linear Model Summary

Calling the model returns the intercept and slope. To get a more useful output use the `summary` function.
In the following we will go over the output of the `summary` function on linear models.
The explanations are mostly taken from this blog entry: [https://feliperego.github.io/blog/2015/10/23/Interpreting-Model-Output-In-R](https://feliperego.github.io/blog/2015/10/23/Interpreting-Model-Output-In-R)

```{r}
#| echo: true
summary(lmod)
```

### Call

* the function that was used to create the model

### Residuals

* summary statistic of the model error
* "How far away are the real values from the model?"
* should follow a normal distribution (e.g. by plotting a histogram)

```{r}
#| echo: false
#| message: false
#| warning: false

library(ggplot2)
library(ggpubr)

bd$pred = predict(lmod, bd)

ggplot(bd, aes(Abundance, Species))+
    geom_point()+
    geom_smooth(method = "lm", se = FALSE, lwd = 0.5)+
    geom_segment(aes(yend = pred, xend = Abundance), col = "red")+
    stat_regline_equation()+
    theme_bw()

```

```{r}
hist(lmod$residuals)
```




### Coefficients

#### Estimate

* again the slope and intercept
* we can expect to observed at least 10.7 different species on a plot (if we collect 103 animals)
* for each additional animal observed, the species count increases by 0.017

```{r}
#| echo: false
#| message: false
#| warning: false



ggplot(bd, aes(Abundance, Species))+
    geom_point()+
    geom_abline(slope = lmod$coefficients[2],
                intercept = lmod$coefficients[1],
                linetype = "dashed", color = "blue")+
    geom_smooth(method = "lm", se = FALSE)+
    scale_x_continuous(limits = c(0, 650))+
    annotate("point", x = 0, y = lmod$coefficients[1], color = "orange", size = 3)+
    annotate("text", x = 12, y = lmod$coefficients[1],
             label = paste0("Intercept = ", round(lmod$coefficients[1], 1)), hjust = 0)+
    annotate("segment", x = 400, xend = 500,
             y = predict(lmod, newdata = data.frame(Abundance = 400)),
             yend = predict(lmod, newdata = data.frame(Abundance = 400)),
             color = "orange")+
    annotate("segment", x = 500, xend = 500,
             y = predict(lmod, newdata = data.frame(Abundance = 400)),
             yend = predict(lmod, newdata = data.frame(Abundance = 500)),
             color = "orange")+
    annotate("text", x = 450, y = 17.2, label = "100")+
    annotate("text", x = 510, y = 18.5,
             label = paste0("100 * ",
                            round(lmod$coefficients[2], 3), " (estimate) \n",
                            "= ", 100 * round(lmod$coefficients[2], 3)),
             hjust = 0)+
    theme_bw()
```


#### Std. Error

* the expected error of the coefficients
* for each additional animal observed, the species number increases by 0.017 +- 0.0037

#### t value

* how many standard deviation is the std. error away from zero?
* far away from zero is better. Reduces the probability that the result is due to chance
* usually not interpreted

#### Pr(>|t|)

* probability that the observed value is larger than t
* small value means that there is a high chance that the relation is not based on chance
* __p values < than 0.05__ is the convention that we can neglect the H0 hypothesis (the model actually depicts a relation)


#### Signif. codes

* a legend for the significance level of the p-value

#### Residuals standard error

* the average deviation of the real values from the model value
* degree of freedom: on how many observations is this value based on?


```{r}
actual_values = bd$Species
predicted_values = predict(lmod, data.frame(Abundance = bd$Abundance))
```


```{r}
#| echo: false
#| message: false
#| warning: false

library(ggplot2)
library(ggpubr)

bd$pred = predict(lmod, bd)

ggplot(bd, aes(Abundance, Species))+
    geom_point()+
    geom_smooth(method = "lm", se = FALSE, lwd = 0.5)+
    geom_segment(aes(yend = pred, xend = Abundance), col = "red")+
    geom_point(aes(x = Abundance, y = pred), col = "black", fill = "white", size = 2, shape = 23)+
    stat_regline_equation()+
    theme_bw()

```





For the specific Abundance values we have in our observed data, we can calculate the error i.e. the deviation of the predicted values from the actual values:

```{r}
# deviation between actual values and predicted values ("error")
residuals = actual_values - predicted_values

# squared residuals: no negative values, large error values are more severe
squared_error = (actual_values - predicted_values)**2
```


However, we also want to give estimates of the models error for abundance values that we have not observed.


```{r}
# number of observations
n = length(actual_values)


# mean squared error
mean(squared_error)

# mean squared error with degrees of freedom
sum(squared_error)/(n-1)

# root mean squared error
sqrt(mean(squared_error))

# root mean squared error with degrees of freedom == Residuals standard error
sqrt(sum(squared_error)/(n-2))
```



#### Multiple R-squared

* How much of the variance is explained by the model?
* Values between 0 and 1
* 0 means no explanation, 1 means perfect fit


```{r}
# how much variation is there in the observed values
total_sum_of_squares = sum(((actual_values) - mean(actual_values))**2)


# how much variation is there in the residuals
residual_sum_of_squares = sum((actual_values - predicted_values)**2)


# divide one by the other:
# if both values are similar, this approaches 1
# if residual sum of squares is very low (i.e. the model is good) this value gets smaller
residual_sum_of_squares / total_sum_of_squares

# Rsq: values close to 1 mean, the residual sum of squares error is low compared to the observed variation
1 - residual_sum_of_squares / total_sum_of_squares
```




#### F-statistics

* Is there a relation between the predictor and the response?
* Is my model better than if all the coefficients are zero?
* Away from 1 is good!
* Depend on number of data points.


## Linear Model Plot

Plotting the linear model gives you 4 different figures that indicate if the model is statistically valid in the first place, i.e. if the residuals follow a normal distribution and if they are homoscedatic.


### Residuals vs. Fitted

* Is it actually a linear relation?
* Points randomly scattered around a horizontal line indicates this


### Normal Q-Q

* Are the residuals normally distributed?
* Points on the 1-1 line indicates this
* Depicted are the actual residuals vs. a theoretical normal distribution

### Scale location

* Are the residuals _homoscedatic_?
* This means that the range of the residuals are more or less equal for the whole data range
* Equally spread points around the line indicates this

### Residuals vs. Levarage

* Are there outliers in the data that have influence on the model?
* In this example, if we would leave out point #12, the model outcome would change.

```{r}
plot(lmod)
```

